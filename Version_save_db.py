import sqlite3
import os
import time
from pathlib import Path

# ==========================================
# 1. ì„¤ì •
# ==========================================
TARGET_TRAIN_FOLDER = "/home/hgyeo/Desktop/Origin_cluster_base_folder/Scissors_done/data_origin"
DB_FILE_NAME = "/home/hgyeo/Desktop/Origin_cluster_base_folder/Scissors_done/Scissors_Origin_dataset.db"

# í•œ ë²ˆì— DBì— ë°€ì–´ ë„£ì„ ë°ì´í„° ë¬¶ìŒ í¬ê¸° (ë©”ëª¨ë¦¬ì™€ ì†ë„ ì¡°ì ˆ)
# í…ìŠ¤íŠ¸ê°€ ì—„ì²­ ê¸¸ë‹¤ë©´ 1000~2000 ì •ë„ê°€ ì ë‹¹, ì§§ë‹¤ë©´ 10000 ì¶”ì²œ
BATCH_SIZE = 2000 

class OptimizedDatasetSaver:
    def __init__(self, db_path):
        self.conn = sqlite3.connect(db_path)
        self.cursor = self.conn.cursor()
        
        # [í•µì‹¬ 1] ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ë¥¼ ìœ„í•œ SQLite ì†ë„ ìµœì í™” ì˜µì…˜
        self.conn.execute('PRAGMA journal_mode = WAL;')  # ì“°ê¸° ì†ë„ ëŒ€í­ í–¥ìƒ
        self.conn.execute('PRAGMA synchronous = NORMAL;') # ì•ˆì •ì„± vs ì†ë„ íƒ€í˜‘
        self.conn.execute('PRAGMA cache_size = 10000;')   # ìºì‹œ ë©”ëª¨ë¦¬ í™•ë³´
        
        self._init_table()

    def _init_table(self):
        # íŒŒì¼ëª…ì´ë‚˜ ê²½ë¡œê°€ ê¸¸ì–´ë„ TEXT íƒ€ì…ì€ 10ì–µ ìê¹Œì§€ ì €ì¥ ê°€ëŠ¥í•˜ë¯€ë¡œ ë¬¸ì œì—†ìŒ
        self.cursor.execute('''
            CREATE TABLE IF NOT EXISTS dataset (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                relative_path TEXT,
                filename TEXT,
                label_content TEXT
            )
        ''')
        self.conn.commit()

    def save_snapshot(self, target_folder):
        target_path = Path(target_folder)
        
        if not target_path.exists():
            print(f"âŒ ê²½ë¡œ ì—†ìŒ: {target_path}")
            return

        print(f"ğŸš€ [ê³ ì„±ëŠ¥ ëª¨ë“œ] ì €ì¥ ì‹œì‘...")
        print(f"   ğŸ“‚ ëŒ€ìƒ: {target_folder}")
        
        buffer = [] # ë°ì´í„°ë¥¼ ë¬¶ì–´ë‘ëŠ” ì„ì‹œ ì°½ê³ 
        total_count = 0
        start_time = time.time()

        for root, dirs, files in os.walk(target_path):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):
                    img_abs_path = Path(root) / file
                    
                    try:
                        # 1. ìƒëŒ€ ê²½ë¡œ (í´ë” êµ¬ì¡°)
                        relative_path = str(img_abs_path.parent.relative_to(target_path))
                        
                        # 2. ë¼ë²¨ ì½ê¸° (ê¸´ í…ìŠ¤íŠ¸ ì²˜ë¦¬)
                        label_content = ""
                        parts = list(img_abs_path.parts)
                        parts_lower = [p.lower() for p in parts]
                        
                        if 'images' in parts_lower:
                            idx = len(parts) - 1 - parts_lower[::-1].index('images')
                            parts[idx] = 'labels'
                            label_path = Path(*parts).with_suffix('.txt')
                            
                            if label_path.exists():
                                # errors='ignore': ì—„ì²­ ê¸´ íŒŒì¼ ì½ë‹¤ê°€ íŠ¹ìˆ˜ë¬¸ì ì—ëŸ¬ë‚˜ë©´ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                                with open(label_path, 'r', encoding='utf-8', errors='ignore') as f:
                                    label_content = f.read()

                        # 3. ë²„í¼ì— ì¶”ê°€ (DBì— ë°”ë¡œ ì•ˆ ë„£ìŒ)
                        # íŠœí”Œ í˜•íƒœë¡œ (ê²½ë¡œ, íŒŒì¼ëª…, ë‚´ìš©) ì €ì¥
                        buffer.append((relative_path, file, label_content))
                        
                        # 4. [í•µì‹¬ 2] ë²„í¼ê°€ ê½‰ ì°¨ë©´ í•œë°©ì— DB íˆ¬ì… (Bulk Insert)
                        if len(buffer) >= BATCH_SIZE:
                            self._flush_buffer(buffer)
                            total_count += len(buffer)
                            buffer = [] # ë²„í¼ ë¹„ìš°ê¸° (ë©”ëª¨ë¦¬ í•´ì œ)
                            
                            # ì§„í–‰ ìƒí™© ì¶œë ¥
                            elapsed = time.time() - start_time
                            speed = total_count / elapsed
                            print(f"â–¶ {total_count}ê°œ ì €ì¥ ì¤‘... (ì†ë„: {speed:.1f}ê°œ/ì´ˆ)")

                    except Exception as e:
                        # íŒŒì¼ëª…ì´ ë„ˆë¬´ ê¸¸ì–´ì„œ OSê°€ ëª» ì½ëŠ” ê²½ìš° ë“± ì˜ˆì™¸ ì²˜ë¦¬
                        print(f"âš ï¸ ìŠ¤í‚µë¨ ({file}): {e}")

        # 5. ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬ (ë§ˆì§€ë§‰ ì°Œêº¼ê¸°)
        if buffer:
            self._flush_buffer(buffer)
            total_count += len(buffer)

        self.conn.commit()
        print("-" * 50)
        print(f"âœ… ì €ì¥ ì™„ë£Œ!")
        print(f"ì´ ë°ì´í„°: {total_count}ê°œ")
        print(f"ì†Œìš” ì‹œê°„: {time.time() - start_time:.1f}ì´ˆ")

    def _flush_buffer(self, data_list):
        """executemanyë¥¼ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë°€ì–´ ë„£ìŒ"""
        try:
            self.cursor.executemany('''
                INSERT INTO dataset (relative_path, filename, label_content)
                VALUES (?, ?, ?)
            ''', data_list)
            self.conn.commit() # ì¤‘ê°„ ì €ì¥ (í˜¹ì‹œ íŠ•ê²¨ë„ ì—¬ê¸°ê¹Œì§€ëŠ” ì €ì¥ë¨)
        except sqlite3.OperationalError as e:
            print(f"âŒ DB ì €ì¥ ì¤‘ ì—ëŸ¬: {e}")
            # ë„ˆë¬´ í° í…ìŠ¤íŠ¸ ë•Œë¬¸ì— ì—ëŸ¬ë‚˜ë©´ ì—¬ê¸°ì„œ ì²˜ë¦¬ ê°€ëŠ¥

    def close(self):
        self.conn.close()

if __name__ == "__main__":
    saver = OptimizedDatasetSaver(DB_FILE_NAME)
    saver.save_snapshot(TARGET_TRAIN_FOLDER)
    saver.close()